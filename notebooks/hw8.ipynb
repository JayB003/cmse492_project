{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471f6988-f74b-4f22-b72c-fe612afdc27f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\jayb0\\\\data\\\\raw\\\\nba_player_stats_2023_24.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     d\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ---- Load\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_RAW)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Basic sanity & subset columns (adjust names to match your file)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m expected_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlayer\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpponent\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHomeAway\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMIN\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFGA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFGM\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3PA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3PM\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     26\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTM\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREB\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAST\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTL\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBLK\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOV\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPF\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPTS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\jayb0\\\\data\\\\raw\\\\nba_player_stats_2023_24.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, pathlib, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, classification_report,\n",
    "                             ConfusionMatrixDisplay, RocCurveDisplay)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# ---- Paths\n",
    "ROOT = pathlib.Path.cwd().parents[1] if (pathlib.Path.cwd().name == \"exploratory\") else pathlib.Path.cwd()\n",
    "DATA_RAW = ROOT / \"data\" / \"raw\" / \"nba_player_stats_2023_24.csv\"\n",
    "DATA_PROC_DIR = ROOT / \"data\" / \"processed\"\n",
    "FIG_DIR = ROOT / \"figures\"\n",
    "for d in [DATA_PROC_DIR, FIG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Load\n",
    "df = pd.read_csv(DATA_RAW)\n",
    "\n",
    "# Basic sanity & subset columns (adjust names to match your file)\n",
    "expected_cols = ['Player','Date','Team','Opponent','HomeAway','MIN','FGA','FGM','3PA','3PM',\n",
    "                 'FTA','FTM','REB','AST','STL','BLK','TOV','PF','PTS']\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Columns missing from CSV. Add or rename as needed:\", missing)\n",
    "\n",
    "# Parse date, sort\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values(['Player','Date'])\n",
    "\n",
    "# Filter reasonable minutes\n",
    "df = df[df['MIN'] > 0].copy()\n",
    "\n",
    "# ---- Target: Above player rolling average prior to game\n",
    "def rolling_pts_avg(g):\n",
    "    return g['PTS'].shift(1).expanding().mean()\n",
    "\n",
    "df['PTS_roll_avg'] = df.groupby('Player', group_keys=False).apply(rolling_pts_avg)\n",
    "df = df.dropna(subset=['PTS_roll_avg']).copy()\n",
    "df['y_above'] = (df['PTS'] > df['PTS_roll_avg']).astype(int)\n",
    "\n",
    "# ---- Save a small processed sample (HW08 asks to save) \n",
    "sample_path = DATA_PROC_DIR / \"nba_sample_2k.csv\"\n",
    "df.sample(min(2000, len(df)), random_state=42).to_csv(sample_path, index=False)\n",
    "\n",
    "# ---- EDA: distributions\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df['MIN'], bins=30)\n",
    "plt.xlabel(\"Minutes\"); plt.ylabel(\"Count\"); plt.title(\"Minutes Distribution\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df['FGA'], bins=30)\n",
    "plt.xlabel(\"FGA\"); plt.ylabel(\"Count\"); plt.title(\"Field Goal Attempts Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"eda_feature_distributions.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# Class balance\n",
    "class_counts = df['y_above'].value_counts().sort_index()\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.bar(['Below Avg (0)', 'Above Avg (1)'], class_counts.values)\n",
    "plt.title(\"Class Balance\"); plt.ylabel(\"Count\")\n",
    "plt.savefig(FIG_DIR / \"eda_class_balance.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# Missingness bar (simple)\n",
    "missing_ratio = df[expected_cols].isna().mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(missing_ratio.index, (100*missing_ratio.values))\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"% Missing\"); plt.title(\"Missingness by Feature\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"eda_missingness.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# Relationship example: Minutes vs Points scatter (downsample for speed)\n",
    "ds = df.sample(min(5000, len(df)), random_state=7)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(ds['MIN'], ds['PTS'], s=6, alpha=0.5)\n",
    "plt.xlabel(\"Minutes\"); plt.ylabel(\"Points\"); plt.title(\"Minutes vs Points\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"eda_minutes_vs_points.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# ---- Train/Val/Test split (stratified)\n",
    "features = ['HomeAway','Team','Opponent','MIN','FGA','FGM','3PA','3PM','FTA','FTM','REB','AST','STL','BLK','TOV','PF']\n",
    "cat = ['HomeAway','Team','Opponent']\n",
    "num = [c for c in features if c not in cat]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['y_above'].copy()\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=123, stratify=y)\n",
    "X_val, X_test,  y_val, y_test  = train_test_split(X_temp, y_temp, test_size=0.50, random_state=123, stratify=y_temp)\n",
    "\n",
    "# ---- Preprocessor\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# ---- Baselines\n",
    "dummy = Pipeline([(\"pre\", pre), (\"clf\", DummyClassifier(strategy=\"most_frequent\"))])\n",
    "dummy.fit(X_train, y_train)\n",
    "y_val_pred = dummy.predict(X_val)\n",
    "print(\"Baseline (Most Frequent) â€” Val F1:\", f1_score(y_val, y_val_pred))\n",
    "\n",
    "# ---- Logistic Regression (strong simple baseline)\n",
    "logit = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", LogisticRegression(max_iter=200, n_jobs=None))\n",
    "])\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "def eval_model(name, model, Xv, yv):\n",
    "    yp = model.predict(Xv)\n",
    "    yp_proba = model.predict_proba(Xv)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "    out = {\n",
    "        \"name\": name,\n",
    "        \"acc\": accuracy_score(yv, yp),\n",
    "        \"prec\": precision_score(yv, yp),\n",
    "        \"rec\": recall_score(yv, yp),\n",
    "        \"f1\": f1_score(yv, yp),\n",
    "        \"rocauc\": roc_auc_score(yv, yp_proba) if yp_proba is not None else np.nan\n",
    "    }\n",
    "    print(name, out)\n",
    "    return out\n",
    "\n",
    "val_dummy  = eval_model(\"Dummy\", dummy, X_val, y_val)\n",
    "val_logit  = eval_model(\"Logit\", logit, X_val, y_val)\n",
    "\n",
    "# ---- Final evaluation on test with best of the two\n",
    "best = logit if val_logit[\"f1\"] >= val_dummy[\"f1\"] else dummy\n",
    "test_metrics = eval_model(\"TEST_\"+(\"Logit\" if best is logit else \"Dummy\"), best, X_test, y_test)\n",
    "\n",
    "# Confusion matrix & ROC\n",
    "plt.figure(figsize=(5,4))\n",
    "ConfusionMatrixDisplay.from_estimator(best, X_test, y_test)\n",
    "plt.title(\"Confusion Matrix (Test)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"cm_test.png\", dpi=180)\n",
    "plt.close()\n",
    "\n",
    "if best is logit:\n",
    "    RocCurveDisplay.from_estimator(best, X_test, y_test)\n",
    "    plt.title(\"ROC Curve (Test)\"); plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"roc_test.png\", dpi=180); plt.close()\n",
    "\n",
    "# ---- Simple metrics table to CSV\n",
    "pd.DataFrame([val_dummy, val_logit, test_metrics]).to_csv(DATA_PROC_DIR / \"baseline_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Done. Figures saved in:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a8b96-ff68-4fa8-885c-50db28dc8bcf",
   "metadata": {},
   "source": [
    "The class distribution shows a modest imbalance, with slightly fewer above-average games, confirming the need to track F1 and ROC-AUC in addition to accuracy. Minutes and field-goal attempts display right-skewed distributions consistent with role differences; a simple scatter of minutes versus points shows a strong positive association, suggesting usage is a primary driver. The majority-class baseline provides a conservative reference; logistic regression with standardized numerical features and one-hot encoded categorical variables materially improves F1 and ROC-AUC on the validation split. These results support proceeding to tree-based models and hyperparameter tuning in the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c64f87-0517-4d2c-959b-6079ba836638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
